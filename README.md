# Churn Prediction Comparative Study

In this project, we perform comparative analysis for churn prediction using various machine learning techniques and aNeural Network. We start by cleaning and preprocessing the data, which involves checking for null values, duplicates, and converting string columns to numerical values. We then split the data into train and test sets and train several models, including decision trees, logistic regression, SVM, KNN, k-means, GMM, random forests and sequential neural network. We evaluate the performance of these models using various metrics including the confusion matrix, precision, recall, F1 score, accuracy, and mean squared error. We then selected the best model based on its performance.  

Next, we perform bagging, boosting, and stacking on the best model to try to improve its performance. Bagging is an ensemble learning method that builds multiple models using different subsets of the training data and combines their predictions to make the final prediction. Boosting is an ensemble learning method that builds a model by iteratively adding weak learners and giving more weight to the misclassified examples in the training set. Stacking is an ensemble learning method that combines the predictions of several base classifiers and trains a higher level classifier to make the final prediction based on those base level predictions. 

Finally, we evaluate the performance of the bagging, boosting, and stacking models and compare them to the best model to see if they have improved the performance. We also visualize the results using various plots to get a better understanding of the behavior of the models.  

This project is a useful resource for anyone interested in churn prediction or ensemble learning techniques.
